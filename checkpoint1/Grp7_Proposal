
### Title

Machine Learning for Health Insurance Premium Forecasting​

### Team

Samiksha Singh - samiksha025 (POC)
Purtee Bhise - Purtee20
Neelam Gujar - NeelamGujar

### Introduction

- What are you trying to do? Articulate your objectives using absolutely no jargon.
We aim to predict the medical insurance costs an individual will incur based on factors like age, BMI, smoking habits, number of dependents, gender, and region. This will help insurance companies determine fair premium rates and allow individuals to estimate their insurance costs.  

- What is new in your approach and why do you think it will be successful?  (be brief here, you can expand more later!)
Instead of using manual calculations or fixed pricing models, we use machine learning algorithms to automatically learn patterns in historical data. By leveraging advanced models (e.g., Random Forest, XGBoost, and Neural Networks), our approach can improve accuracy, reduce bias, and make pricing more data-driven.

- Who cares? If you are successful, what difference will it make?

Stakeholders
-Primary Stakeholders:
  - Insurance Companies – Need to price policies accurately while minimizing risk.
  - Policyholders (Customers) – Want fair and competitive premium prices.
  - Actuaries & Underwriters – Require advanced tools to estimate premium costs efficiently.

-Secondary Stakeholders:
  - Healthcare Providers – Insurance coverage impacts medical services accessibility.
  - Government & Regulators – Need transparency in premium calculations.
  - Data Scientists & ML Engineers – Develop models to improve premium pricing accuracy.

  1. Insurance companies can set more accurate and fair premiums, reducing financial risks.  
  2. Customers (policyholders) can estimate their insurance costs upfront and make informed decisions.  
  3. The healthcare industry can use insights from predictive modeling for better policy structuring.  
  4. Regulators can ensure fair and transparent pricing, avoiding discrimination in premium calculation.  

### Literature Review

>> Current Methods in Medical Insurance Premium Prediction:
 
Traditionally, medical insurance premiums have been determined using actuarial models that assess risk based on demographic factors, medical history, and lifestyle choices. These models often employ statistical techniques such as linear regression to estimate costs. However, recent studies have explored the application of machine learning (ML) techniques to enhance prediction accuracy and provide more personalized premium assessments.
 
For instance, a study by Orji and Ukwandu (2024) deployed ensemble ML models, including Extreme Gradient Boosting (XGBoost), Gradient Boosting Machine (GBM), and Random Forest, to predict medical insurance costs. They utilized explainable artificial intelligence methods to identify key factors influencing premium prices, demonstrating that ML models can outperform traditional actuarial approaches in predictive accuracy and interpretability [^1].
 
Another research effort by Cenita et al. (2023) evaluated the performance of regression models such as Linear Regression, Gradient Boosting, and Support Vector Machine in predicting medical insurance costs. Their findings indicated that Gradient Boosting achieved the highest R² score and the lowest Root Mean Square Error (RMSE), suggesting its superiority over other models in capturing complex relationships within the data [^2].
 
Despite these advancements, current ML approaches face limitations, including challenges in model interpretability, potential overfitting, and the need for large, high-quality datasets. Additionally, many models do not account for temporal changes in healthcare costs or integrate real-time data, which can affect their predictive accuracy.
 
>> Stakeholder Needs
 
Identifying and understanding the needs of stakeholders is crucial in developing effective medical insurance premium prediction models. The primary stakeholders include:
 
1. Insurance Companies: Require accurate and reliable models to set fair premiums, manage risk, and maintain profitability. They need models that can handle large datasets, provide interpretable results, and adapt to changing healthcare trends.
 
2. Policyholders (Customers): Seek transparency in how premiums are calculated and desire fair pricing that reflects their individual risk profiles. They benefit from models that consider personalized factors and offer understandable explanations for premium determinations.
 
3. Healthcare Providers: Interested in models that can predict patient costs to manage care plans effectively. Accurate predictions assist in resource allocation and financial planning within healthcare facilities.
 
4. Regulatory Bodies: Demand models that ensure compliance with legal standards, promote fairness, and prevent discrimination. They require transparency in the modeling process and outcomes to uphold ethical standards in premium setting.
 
5. Data Scientists and ML Practitioners: Need access to comprehensive datasets and advanced tools to develop, test, and validate predictive models. They also require collaboration with domain experts to ensure the models are clinically and actuarially relevant.
 
Addressing these needs involves developing models that are not only accurate but also interpretable, transparent, and adaptable to evolving data landscapes. Incorporating stakeholder feedback throughout the model development process can enhance the applicability and acceptance of predictive models in medical insurance premium determination.

>> Citation: 
[^1]: Orji, U., & Ukwandu, E. (2024). Machine Learning For An Explainable Cost Prediction of Medical Insurance. *Machine Learning with Applications*, 15, 100516. [Link](https://arxiv.org/abs/2311.14139)
 
[^2]: Cenita, J. A. S., Asuncion, P. R. F., & Victoriano, J. M. (2023). Performance Evaluation of Regression Models in Predicting the Cost of Medical Insurance. *arXiv preprint arXiv:2304.12605*. [Link](https://arxiv.org/abs/2304.12605)
 


#### Data

>> Data Overview  
The dataset used in this project is the Medical Insurance Cost Dataset from Kaggle, which consists of 100000+ records of individuals along with key attributes affecting medical insurance costs. The dataset contains a mix of numerical and categorical features essential for predicting insurance premiums.

The dataset used in this project is the Insurance Data for Machine Learning from Kaggle, which contains records of individuals with various attributes influencing medical insurance costs. This dataset provides a more comprehensive view of insurance premium determinants compared to traditional datasets by incorporating demographic, lifestyle, and medical history information.  

Dataset contains 12 columns as follow:
1. age (numerical)
2. gender (categorical)
3. bmi (numerical)
4. children (numerical)
5. smoker (binary categorical)
6. region (categorical)
7. medical_history (categorical)
8. family_medical_history (categorical)
9. Exercise_frequency (categorical)
10. Occupation (categorical)
11. Coverage_label (categorical)
12. charges (target variable)

>>> Dataset link: https://www.kaggle.com/datasets/sridharstreaks/insurance-data-for-machine-learning?resource=download
 

#### Methods

>>> Modeling Approach
 
 1. Data Collection, Exploration & Data Preprocessing

- Loaded the dataset and performed exploratory data analysis (EDA) to understand feature distributions.  ​
- Identified key factors affecting insurance costs (age, BMI, smoking habits, number of dependents, and region).  ​
- Handling Missing Values: Check for null values and apply appropriate imputation if required.  
- Encoding Categorical Variables:  
- Convert categorical features (gender, smoker, region, medical_history, exercise_frequency, occupation, coverage_level) using One-Hot Encoding or Label Encoding.  
- Feature Scaling:  
 - Standardize numerical variables (age, bmi, children, charges) for better performance in certain models.  
- Train-Test Split:  
  - Divide the dataset into training (80%) and testing (20%) sets to assess model performance.  
  
2. Model Selection
- Baseline Model:  
  - Linear Regression – Establishes a simple benchmark for prediction accuracy.  
 
- Advanced Models:  
  - Decision Tree Regressor – Captures non-linear relationships between features.  
  - Random Forest Regressor – An ensemble learning approach that improves prediction robustness.  
  - Gradient Boosting (XGBoost) – Uses boosting techniques to minimize prediction errors.  
  - Artificial Neural Networks (ANN) – Deep learning-based model to capture complex interactions between variables.  
 
3. Model Evaluation Metrics
To measure model effectiveness, we will use the following metrics:  
- Mean Absolute Error (MAE) – Measures the average magnitude of errors in predictions.  
- Mean Squared Error (MSE) – Penalizes larger errors more heavily, ensuring better performance tracking.  
- R-squared (R²) Score – Evaluates how well the independent variables explain variance in insurance charges.  
 
Cross-validation techniques, such as K-Fold Cross-Validation, will be applied to ensure model robustness.
 
4. Hyperparameter Tuning & Optimization
- GridSearchCV / RandomizedSearchCV will be used to fine-tune model hyperparameters for optimal performance.  
- Feature selection techniques may be applied to identify the most important predictors influencing insurance charges.
 

### Project Plan

>> From March 4 to March 11, the focus will be on conducting a stakeholder analysis and performing Exploratory Data Analysis (EDA). This will include identifying correlations between features, handling missing values and outliers, and understanding key trends in the dataset. By the end of this phase, we aim to have a clear understanding of how different variables contribute to insurance costs.  
 
>> Between March 11 and March 18, data preprocessing will take place. This involves encoding categorical variables, scaling numerical features, and preparing the dataset for modeling. The first baseline model, using Linear Regression, will be implemented to provide an initial benchmark for evaluating predictions. This phase will conclude with a clean and structured dataset, along with preliminary insights from the baseline model.  
 

>> From March 18 to March 25, advanced machine learning models such as Decision Trees, Random Forests, and Gradient Boosting will be trained. Hyperparameter tuning will be applied to optimize model performance. Feature selection techniques will be explored to improve prediction accuracy by identifying the most relevant features affecting insurance charges. The goal of this phase is to compare multiple models and determine the most promising approaches for further refinement.  
 
>> During March 25 to April 1, Artificial Neural Networks (ANNs) will be introduced to analyze deeper patterns within the data. The results from neural networks will be compared with those from traditional ML models to evaluate improvements in accuracy. Cross-validation will be performed to ensure that the models generalize well to unseen data. By the end of this phase, the best-performing models will be finalized for evaluation.  
 
>> From April 1 to April 8, model evaluation will take place using performance metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared scores. Feature importance analysis will be conducted using SHAP or LIME to enhance interpretability. This phase will focus on extracting key insights that can be used to explain the model’s predictions to stakeholders.  
 
>> Between April 8 and April 15, an interactive dashboard will be developed using Tableau or Streamlit. The dashboard will allow users to input personal attributes and receive an estimated insurance cost based on the trained models. This will enhance the project’s usability and provide a practical implementation of the findings.  
 
>> From April 15 to April 22, efforts will be directed toward refining the final report and creating visualizations for the presentation. Results will be validated, and necessary adjustments will be made to improve clarity and impact. The goal is to have a comprehensive draft ready for review.  
 
>> Finally, from April 22 to April 29, the project will undergo a final review. Presentation slides will be prepared, and the report will be finalized. By the end of this phase, the complete project, including all deliverables, will be ready for submission.  


### Risks

- One of the primary risks in this project is data quality issues, including missing values, incorrect data, or biases that could affect model predictions. To mitigate this, thorough data cleaning and imputation techniques will be applied, and data balancing techniques will be explored if necessary.  
 
- Another risk is model overfitting, where the model performs exceptionally well on training data but fails to generalize to unseen data. To address this, techniques such as cross-validation, regularization, and optimal hyperparameter selection will be implemented to ensure the model remains robust and reliable.  

- Model interpretability is another potential challenge, especially with complex algorithms like Artificial Neural Networks. Since interpretability is crucial for stakeholders, SHAP or LIME will be used to provide explanations on feature importance and decision-making within the model.  
 
- Computational constraints may arise, particularly when training resource-intensive models like XGBoost or deep learning networks. To manage this, feature selection techniques will be applied to reduce dataset dimensionality, and cloud-based computing solutions may be leveraged if needed.  
 
- There is also a risk that stakeholder needs may evolve over time, requiring adjustments to the model or additional feature integration. To mitigate this, continuous feedback loops will be maintained, allowing for iterative improvements based on stakeholder inputs and findings.  
 
- Lastly, time constraints pose a challenge, given the complexity of the tasks involved. To ensure smooth progress, the project will adhere to a structured timeline, with critical tasks prioritized, allowing flexibility for refinements while meeting deadlines.  
 
- By proactively addressing these risks and maintaining a structured workflow, the project is expected to successfully deliver an accurate and interpretable machine learning model for predicting medical insurance costs.
has context menu
